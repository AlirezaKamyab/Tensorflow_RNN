{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2767f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d74ea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    'I really love progarmming',\n",
    "    'It is often seen as something difficult but beautiful',\n",
    "    'This is another text!',\n",
    "    'Do you like something else?'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c1eebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=50)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dd62c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is': 1, 'something': 2, 'i': 3, 'really': 4, 'love': 5, 'progarmming': 6, 'it': 7, 'often': 8, 'seen': 9, 'as': 10, 'difficult': 11, 'but': 12, 'beautiful': 13, 'this': 14, 'another': 15, 'text': 16, 'do': 17, 'you': 18, 'like': 19, 'else': 20}\n"
     ]
    }
   ],
   "source": [
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dc3ad3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 4, 5, 6], [7, 1, 8, 9, 10, 2, 11, 12, 13], [14, 1, 15, 16], [17, 18, 19, 2, 20]]\n"
     ]
    }
   ],
   "source": [
    "print(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd02ba0",
   "metadata": {},
   "source": [
    "If some word is not in the word_index that is previously fit, it will not be in the sequences;\n",
    "E.g. I would like another cup of coffee\n",
    "Since words like would, cup, of, coffee are not in the word_index the output will be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37287364",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [\n",
    "    'I would like another cup of coffee',\n",
    "    'I really like something beautiful'\n",
    "]\n",
    "sequences_test = tokenizer.texts_to_sequences(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cbd1e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 19, 15], [3, 4, 19, 2, 13]]\n"
     ]
    }
   ],
   "source": [
    "print(sequences_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b7c4fc",
   "metadata": {},
   "source": [
    "We don't like to end up losing words like that since it might change the meaning of the sequences. Like above we will end up with \"I like another\".\n",
    "We would like to write a special token like \\<UNK\\> or \\<OOV\\> as unknown or out of vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41456e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=50, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(texts)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7fa8fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 1, 20, 16, 1, 1, 1], [4, 5, 20, 3, 14]]\n"
     ]
    }
   ],
   "source": [
    "tests = [\n",
    "    'I would like another cup of coffee',\n",
    "    'I really like something beautiful'\n",
    "]\n",
    "sequences_test = tokenizer.texts_to_sequences(tests)\n",
    "print(sequences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fdfe1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OOV>': 1, 'is': 2, 'something': 3, 'i': 4, 'really': 5, 'love': 6, 'progarmming': 7, 'it': 8, 'often': 9, 'seen': 10, 'as': 11, 'difficult': 12, 'but': 13, 'beautiful': 14, 'this': 15, 'another': 16, 'text': 17, 'do': 18, 'you': 19, 'like': 20, 'else': 21}\n"
     ]
    }
   ],
   "source": [
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07ff3d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = pad_sequences(sequences, padding='post', maxlen=10, truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33a840ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  4,  5,  6,  0,  0,  0,  0,  0,  0],\n",
       "       [ 7,  1,  8,  9, 10,  2, 11, 12, 13,  0],\n",
       "       [14,  1, 15, 16,  0,  0,  0,  0,  0,  0],\n",
       "       [17, 18, 19,  2, 20,  0,  0,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6804805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
